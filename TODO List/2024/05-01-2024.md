### Simulation Env

- Trim the image names
  - Template: x-y-yaw_indicator-vision.png
- Trim the olfaction data
  - Olfaction data should contain:
    - Global Wind Direction: using the one where the robot facing forward 
    - Global Wind Speed: using the one where the robot facing forward
    - Chemical Concentration: depending on the direction
  - Template: x-y-yaw_indicator-olfaction.csv
- Save vision and olfaction after trim into a folder, call it meta data.

## Updated in 05-13-2024
### Test the Sim Env
- [ ] At each odor source cell, show the image and odor information (chemical concentration, wind speed, wind dir)

### Implement the LLM to the Vision-Olfaction Navigation
#### The vision branch
- [ ] Use CLIPSeg (or other vision detector) to process input images at a random cell
  - The goal is to let the CLIPSeg to indicate which object is the possible odor source object   
#### The Olfaction branch
- [ ] Import the wind/chemical information into LLM
#### The Decision-making Model
- [ ] This is a LLM to process vision and olfaction detection results

- Create an image to demonstrate the grid positions
