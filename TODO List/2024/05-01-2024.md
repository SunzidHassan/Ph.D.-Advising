### Simulation Env

- Trim the image names
  - Template: x-y-yaw_indicator-vision.png
- Trim the olfaction data
  - Olfaction data should contain:
    - Global Wind Direction: using the one where the robot facing forward 
    - Global Wind Speed: using the one where the robot facing forward
    - Chemical Concentration: depending on the direction
  - Template: x-y-yaw_indicator-olfaction.csv
- Save vision and olfaction after trim into a folder, call it meta data.

## Updated in 05-13-2024
### Test the Sim Env
- olfaction_data.csv:
  - [ ] At each odor source cell, show the image and odor information (chemical concentration, wind speed, wind dir)
  - Object: Chemical/Wind dir/Wind Speed
  - Humidifier Box: 720	112.51	0.12
  - Cola:722	97.05	0.19
  - Humdifier:727	206.84	0.37
  - First Aid Box:715	280.28	0.13
  - Bottle: 711	226.16	0.13
- olfaction_data_2.csv:
  - Re-meausre the two rows at the source locations (only olfaction data)
  - Starting at (2.2, 2.6) -> (2.3, 2.0)
  - Take measurements on all 4 directions


### Implement the LLM to the Vision-Olfaction Navigation
#### The vision branch
- [ ] Use CLIPSeg (or other vision detector) to process input images at a random cell
  - The goal is to let the CLIPSeg to indicate which object is the possible odor source object   
#### The Olfaction branch
- [ ] Import the wind/chemical information into LLM
#### The Decision-making Model
- [ ] This is a LLM to process vision and olfaction detection results

- Create an image to demonstrate the grid positions
